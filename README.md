# Meta_Hyperband_implementation
This is the source code for "Meta-Hyperband: Hyperparameter optimizationwith meta-learning and Coarse-to-Fine" paper, accepted by IDEAL2020.
Authors: Samin Payrosangari1, Afshin Sadeghi1,2B,Damien Graux3, and Jens Lehmann1,21Department of Computer Science, University of Bonn, Germany2Fraunhofer IAIS, Sankt Augustin, Germany3ADAPT SFI Research Centre, Trinity College Dublin, Irelandsaminpayro@gmail.com, sadeghi@cs.uni-bonn.de,damien.graux@adaptcentre.ie, jens.lehmann@cs.uni-bonn.de


Abstract. Hyperparameter optimization is one of the main pillars of ma-chine learning algorithms. In this paper, we introduce Meta-Hyperband: aHyperband based algorithm that improves the hyperparameter optimiza-tion by adding levels of exploitation. Unlike Hyperband method, which isa pure exploration bandit-based approach for hyperparameter optimiza-tion, our meta approach generates a trade-off between exploration andexploitation by combining the Hyperband method with meta-learning andCoarse-to-Fine modules. We analyze the performance of Meta-Hyperbandon various datasets to tune the hyperparameters of CNN and SVM. Theexperiments indicate that in many cases Meta-Hyperband can discoverhyperparameter configurations with higher quality than Hyperband, us-ing similar amounts of resources. In particular, we discovered a CNNconfiguration for classifying CIFAR10 dataset which has a 3% higherperformance than the configuration founded by Hyperband, and is also0.3% more accurate than the best-reported configuration of the Bayesianoptimization approach. Additionally, we release a publicly available poolof historically well-performed configurations on several datasets for CNNand SVM to ease the adoption of Meta-Hyperband.

