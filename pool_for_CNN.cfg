#Meta-learning pool for the "cuda-convnet 18% error architecture of Alex Krizhevsky" as the CNN model (cuda-convnet2)
#cfg file format, which can be direcly fed into the Meta-Hyperband algorithm by installing required python libraries
[1]
name = mnist
init_learning_rate = 0.0134387291125
conv1_l2 = 2.51806295582
conv2_l2 = 0.531019446636
conv3_l2 = 0.000819729012975
fc_l2 = 0.819018764514
scale = 5.78952692531e-05
poww = 1.56018414927
learning_rate_reduction = 0
epsw = dexp[base=0.0134387291125;tgtFactor=10;numSteps=0]
test_loss = 0.061231
epochs=300

[2]
name = fashionmnist
init_learning_rate = 0.010346329155491047
conv1_l2 = 0.00013062068697357147
conv2_l2 = 0.00010788406304327284
conv3_l2 = 0.0003551538649683333
fc_l2 = 0.052802381850789795
scale = 0.003913255138183903
poww = 0.21141671907694315
learning_rate_reduction = 2
epsw = dexp[base=0.0103463291555;tgtFactor=10;numSteps=2]
test_loss = 0.232118
epochs=300

[3]
name = cifar
init_learning_rate = 0.016728495840218453
conv1_l2 = 5.759245362643967e-05
conv2_l2 = 0.007427994243317873
conv3_l2 = 0.02754976447626608
fc_l2 = 0.005638413030032732
scale = 1.0021418264854512e-05
poww = 0.3623707822041795
learning_rate_reduction = 1
epsw = dexp[base=0.0167284958402;tgtFactor=10;numSteps=1]
test_loss_logprob = 0.947393
test_loss = 0.281600
image_size = 32
epochs=300

[4]
name = cifar
init_learning_rate = 0.0185129779007
conv1_l2 = 0.000131230264917
conv2_l2 = 0.000121509836424
conv3_l2 = 9.40709315743e-05
fc_l2 = 0.178101728146
scale = 1.65262610874e-05
poww = 0.589980565448
learning_rate_reduction = 0
epsw = dexp[base=0.0185129779007;tgtFactor=10;numSteps=0]
test_loss_logprob = 0.594093
test_loss = 0.195400
image_size = 24
epochs=300

[5]
name = cifar100
init_learning_rate = 0.017655899491
conv1_l2 = 0.00745670122
conv2_l2 = 0.02946789864
conv3_l2 = 0.00048997654567
fc_l2 = 0.0207643578
scale = 0.00019578974
poww = 0.12589096543
learning_rate_reduction = 0
epsw = dexp[base=0.017655899491;tgtFactor=10;numSteps=0]
test_loss_logprob = 4.58743
test_loss = 0.7986
epochs=300

[6]
name = cifar
init_learning_rate = 0.019658656577168837
conv1_l2 = 0.0004182220710546981
conv2_l2 = 0.00011051592191666143
conv3_l2 = 0.00023844011640710168
fc_l2 = 0.15560039825966854
scale = 0.00016242951087218772
poww = 0.5112506100862174
learning_rate_reduction = 1
epsw = dexp[base=0.0196586565772;tgtFactor=10;numSteps=1]
test_loss_logprob = 0.560596
test_loss = 0.186600
image_size = 24
epochs=300

[7]
name = fashion_mnist
init_learning_rate = 0.00153665555438
conv1_l2 = 0.00906512602285
conv2_l2 = 0.0108762257476
conv3_l2 = 0.00116440477328
fc_l2 = 0.00827527143999
scale = 0.00109946344077
poww = 1.26737548904
learning_rate_reduction = 2
epsw = dexp[base=0.00153665555438;tgtFactor=10;numSteps=2]
test_loss_logprob = 0.225355
test_loss = 0.079000
image_size = 28
epochs=300

[8]
name = cifar
init_learning_rate = 0.0196952932615
conv1_l2 = 0.000413837466957
conv2_l2 = 0.000118260355611
conv3_l2 = 0.00025820898077
fc_l2 = 0.155657092296
scale = 0.000237956752155
poww = 0.506231084998
learning_rate_reduction = 0
epsw = dexp[base=0.0196952932615;tgtFactor=10;numSteps=0]
test_loss_logprob = 0.535063
test_loss = 0.165700
image_size = 24
epochs=300
[9]
name = svhn
init_learning_rate = 0.0188748034073
conv1_l2 = 0.000189299767967
conv2_l2 = 0.0112111048725
conv3_l2 = 0.00031564380632
fc_l2 = 0.120203802944
scale = 1.23701313189e-05
poww = 2.64856622206
learning_rate_reduction = 1
epsw = dexp[base=0.0188748034073;tgtFactor=10;numSteps=1]
test_loss_logprob = 0.284940
test_loss = 0.080042
epochs=600

[10]
name = cifar100
init_learning_rate = 0.00487515637532
conv1_l2 = 0.0006578805983
conv2_l2 = 0.0719772502518
conv3_l2 = 0.00185554856845
fc_l2 = 0.0297429411773
scale = 0.000217557444908
poww = 2.26884988898
learning_rate_reduction = 2
epsw = dexp[base=0.00487515637532;tgtFactor=10;numSteps=2]
test_loss_logprob = 2.5655457 
test_loss = 0.5764
epochs=300

[11]
name = cifar100
init_learning_rate = 0.0123218576316
conv1_l2 = 0.0071026611165
conv2_l2 = 0.0303759088973
conv3_l2 = 0.000533516289135
fc_l2 = 0.0193831232866
scale = 0.000195304715961
poww = 0.126994348537
learning_rate_reduction = 0
epsw = dexp[base=0.0123218576316;tgtFactor=10;numSteps=0]
test_loss_logprob = 4.699986
test_loss = 0.8300
image_size = 24
epochs=300

[12]
name = mnist
init_learning_rate = 0.00608425767762
conv1_l2 = 0.00190641193074
conv2_l2 = 0.00109786294358
conv3_l2 = 0.00174476607462
fc_l2 = 0.00684942038934
scale = 0.000416673392626
poww = 2.24349993429
learning_rate_reduction = 2
epsw = dexp[base=0.00608425767762;tgtFactor=10;numSteps=2]
test_loss_logprob = 0.097952
test_loss = 0.029700
image_size = 28
epochs=300


[13]
name = svhn
init_learning_rate = 0.00225328462531
conv1_l2 = 0.0018159322993
conv2_l2 = 0.00044097581407
conv3_l2 = 0.000866783121175
fc_l2 = 0.0184323882837
scale = 5.60628369863e-06
poww = 0.697317455421
learning_rate_reduction = 2
epsw = dexp[base=0.00225328462531;tgtFactor=10;numSteps=2]
test_loss_logprob = 0.222038
test_loss = 0.058208
image_size = 32
epochs=600

[14]
name = svhn
init_learning_rate = 0.010346329155491047
conv1_l2 = 0.00013062068697357147
conv2_l2 = 0.00010788406304327284
conv3_l2 = 0.0003551538649683333
fc_l2 = 0.052802381850789795
scale = 0.003913255138183903
poww = 0.21141671907694315
learning_rate_reduction = 2
epsw = dexp[base=0.0103463291555;tgtFactor=10;numSteps=2]
test_loss_logprob = 0.241362
test_loss = 0.066167
epochs=600

[15]
name = cifar100
init_learning_rate = 0.00474479929153
conv1_l2 = 0.073277510821
conv2_l2 = 0.00775686152772
conv3_l2 = 0.000134358736336
fc_l2 = 0.0143881821142
scale = 0.000120793700073
poww = 2.2022495054
learning_rate_reduction = 2
epsw = dexp[base=0.00474479929153;tgtFactor=10;numSteps=2]
test_loss_logprob = 2.86479478987 
test_loss = 0.5893
epochs=300

[16]
name = svhn
init_learning_rate = 0.0110716022029
conv1_l2 = 0.000116971443068
conv2_l2 = 0.000107728680251
conv3_l2 = 0.000328765805444
fc_l2 = 0.0454092296777
scale = 0.0042740548608
poww = 0.226678579786
learning_rate_reduction = 2
epsw = dexp[base=0.0110716022029;tgtFactor=10;numSteps=2]
test_loss_logprob = 0.276490
test_loss = 0.079625
epochs=600

[17]
name = cifar
init_learning_rate = 0.00240887686438
conv1_l2 = 0.00181289024681
conv2_l2 = 0.00047914029753
conv3_l2 = 0.000940363252032
fc_l2 = 0.0173303530849
scale = 6.16014224579e-06
poww = 0.631158789966
learning_rate_reduction = 2
epsw = dexp[base=0.00240887686438;tgtFactor=10;numSteps=2]
test_losslogprob = 0.486012
test_loss = 0.146800
epochs=300

[18]
name = cifar
init_learning_rate = 0.00357758535587
conv1_l2 = 0.000736411787813
conv2_l2 = 0.000306143984539
conv3_l2 = 0.00246048968656
fc_l2 = 0.0266072043066
scale = 1.11435621648e-05
poww = 1.32249991339
learning_rate_reduction = 2
epsw = dexp[base=0.00357758535587;tgtFactor=10;numSteps=2]
test_loss_logprob = 0.466353
test_loss = 0.147600
epochs=300

[19]
name = cifar
init_learning_rate = 0.00234351694196
conv1_l2 = 0.00173952153463
conv2_l2 = 0.000448238752839
conv3_l2 = 0.000866188582741
fc_l2 = 0.0200394102517
scale = 5.12249961602e-06
poww = 0.736299748814
learning_rate_reduction = 2
epsw = dexp[base=0.00234351694196;tgtFactor=10;numSteps=2]
test_loss_logprob = 0.494128
test_loss = 0.150800
epochs=300

[20]
name = cifar
init_learning_rate = 0.00477958818204
conv1_l2 = 0.0491726761798
conv2_l2 = 0.00251075709604
conv3_l2 = 0.000171390115113
fc_l2 = 0.0142638772724
scale = 4.47540749837e-05
poww = 1.4191221296
learning_rate_reduction = 2
epsw = dexp[base=0.00477958818204;tgtFactor=10;numSteps=2]
test_loss_logprob = 0.588533
test_loss = 0.202100
epochs=300

[21]
name = svhn
init_learning_rate = 0.00820293639354
conv1_l2 = 9.94536810875e-05
conv2_l2 = 0.000410643141028
conv3_l2 = 0.00375952571918
fc_l2 = 0.160426840674
scale = 9.54519519619e-05
poww = 0.180110842219
learning_rate_reduction = 0
epsw = dexp[base=0.00820293639354;tgtFactor=10;numSteps=0]
test_loss_logprob = 0.401270
test_loss = 0.093667
epochs=600

[22]
name = svhn
init_learning_rate = 0.00105988895013
conv1_l2 = 0.0708725882379
conv2_l2 = 0.000844128536207
conv3_l2 = 0.0223566628009
fc_l2 = 0.0106043598897
scale = 2.82094714698e-05
poww = 1.2568367701
learning_rate_reduction = 2
epsw = dexp[base=0.00105988895013;tgtFactor=10;numSteps=2]
test_loss_logprob = 0.314802
test_loss = 0.089917
epochs=600

[23]
name = svhn
init_learning_rate = 0.0212285364149
conv1_l2 = 0.000415122890445
conv2_l2 = 0.000110992560964
conv3_l2 = 0.000265238844013
fc_l2 = 0.162534565257
scale = 0.00024982044675
poww = 0.490699114144
learning_rate_reduction = 1
epsw = dexp[base=0.0212285364149;tgtFactor=10;numSteps=1]
test_loss_logprob = 0.240413
test_loss = 0.066625
epochs=600

[24]
name = svhn
init_learning_rate = 0.0042292560349
conv1_l2 = 0.000381031859058
conv2_l2 = 6.68745005588e-05
conv3_l2 = 0.0315337151371
fc_l2 = 0.00816797718926
scale = 3.37764785099e-05
poww = 0.347196534204
learning_rate_reduction = 2
epsw = dexp[base=0.0042292560349;tgtFactor=10;numSteps=2]
test_loss_logprob = 0.238161
test_loss = 0.064833
epochs=600
[25]
name = svhn
init_learning_rate = 0.010346329155491047
conv1_l2 = 0.00013062068697357147
conv2_l2 = 0.00010788406304327284
conv3_l2 = 0.0003551538649683333
fc_l2 = 0.052802381850789795
scale = 0.003913255138183903
poww = 0.21141671907694315
learning_rate_reduction = 2
epsw = dexp[base=0.0103463291555;tgtFactor=10;numSteps=2]
test_loss_logprob = 0.283331
test_loss = 0.081208
epochs=600
[26]
name = svhn
init_learning_rate = 0.0215513234764
conv1_l2 = 0.000123578580663
conv2_l2 = 0.000122255779339
conv3_l2 = 7.84582907698e-05
fc_l2 = 0.159775276399
scale = 1.49735655645e-05
poww = 0.515917737998
learning_rate_reduction = 0
epsw = dexp[base=0.0215513234764;tgtFactor=10;numSteps=0]
test_loss_logprob = 0.233492
test_loss = 0.062667
epochs=600

[27]
name = svhn
init_learning_rate = 0.0186011146494
conv1_l2 = 0.000123786704625
conv2_l2 = 0.000122811599939
conv3_l2 = 8.67322534064e-05
fc_l2 = 0.16791799527
scale = 1.75271805304e-05
poww = 0.564447852677
learning_rate_reduction = 0
epsw = dexp[base=0.0186011146494;tgtFactor=10;numSteps=0]
test_loss_logprob = 0.246113
test_loss = 0.066958
epochs=600








